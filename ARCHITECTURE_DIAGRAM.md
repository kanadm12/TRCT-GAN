# TRCT-GAN Architecture Diagram

## Complete System Architecture

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              TRCT-GAN SYSTEM                                 │
└─────────────────────────────────────────────────────────────────────────────┘

INPUT STAGE
┌──────────────────────┐         ┌──────────────────────┐
│   Frontal X-ray      │         │   Lateral X-ray      │
│   (1 × 128 × 128)    │         │   (1 × 128 × 128)    │
└──────────┬───────────┘         └──────────┬───────────┘
           │                                 │
           ▼                                 ▼

ENCODER STAGE (2D Feature Extraction)
┌──────────────────────┐         ┌──────────────────────┐
│  Encoder (Frontal)   │         │  Encoder (Lateral)   │
│                      │         │                      │
│  ┌────────────────┐  │         │  ┌────────────────┐  │
│  │ Initial Conv   │  │         │  │ Initial Conv   │  │
│  │ (7×7, 64 ch)   │  │         │  │ (7×7, 64 ch)   │  │
│  └────────┬───────┘  │         │  └────────┬───────┘  │
│           │          │         │           │          │
│  ┌────────▼───────┐  │         │  ┌────────▼───────┐  │
│  │ Dense Block 1  │  │         │  │ Dense Block 1  │  │
│  │ (64 ch)        │  │         │  │ (64 ch)        │  │
│  └────────┬───────┘  │         │  └────────┬───────┘  │
│           │↓ Pool    │         │           │↓ Pool    │
│  ┌────────▼───────┐  │         │  ┌────────▼───────┐  │
│  │ Dense Block 2  │  │         │  │ Dense Block 2  │  │
│  │ (128 ch)       │  │         │  │ (128 ch)       │  │
│  └────────┬───────┘  │         │  └────────┬───────┘  │
│           │↓ Pool    │         │           │↓ Pool    │
│  ┌────────▼───────┐  │         │  ┌────────▼───────┐  │
│  │ Dense Block 3  │  │         │  │ Dense Block 3  │  │
│  │ (256 ch)       │  │         │  │ (256 ch)       │  │
│  └────────┬───────┘  │         │  └────────┬───────┘  │
│           │↓ Pool    │         │           │↓ Pool    │
│  ┌────────▼───────┐  │         │  ┌────────▼───────┐  │
│  │ Dense Block 4  │  │         │  │ Dense Block 4  │  │
│  │ (512 ch)       │  │         │  │ (512 ch)       │  │
│  └────────┬───────┘  │         │  └────────┬───────┘  │
│           │          │         │           │          │
│  ┌────────▼───────┐  │         │  ┌────────▼───────┐  │
│  │  2D AIA Module │  │         │  │  2D AIA Module │  │
│  │  (Attention)   │  │         │  │  (Attention)   │  │
│  └────────┬───────┘  │         │  └────────┬───────┘  │
└───────────┼──────────┘         └───────────┼──────────┘
            │                                 │
            │    Bottleneck Features          │
            │    (512 × 16 × 16)              │
            └──────────┬──────────────────────┘
                       │
                       ▼

VIEW FUSION STAGE
┌──────────────────────────────────────┐
│        View Fusion Module            │
│                                      │
│  ┌────────────────────────────────┐  │
│  │  Attention Weights Generator   │  │
│  │  (learns view importance)      │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │  Weighted Feature Combination  │  │
│  │  frontal * w1 + lateral * w2   │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │     Fusion Convolution         │  │
│  └──────────────┬─────────────────┘  │
└─────────────────┼────────────────────┘
                  │
        Fused Features (512 × 16 × 16)
                  │
                  ▼

TRANSFORMER STAGE (2D → 3D Conversion)
┌──────────────────────────────────────┐
│      Transformer Bridge              │
│                                      │
│  ┌────────────────────────────────┐  │
│  │  2D → 1D Flattening           │  │
│  │  (512, 16, 16) → (256, 512)   │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │  Positional Encoding          │  │
│  │  (spatial information)        │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │  Multi-Head Self-Attention    │  │
│  │  Layer 1 (8 heads)            │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │  Multi-Head Self-Attention    │  │
│  │  Layer 2-6 (8 heads each)     │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │  Depth Query Generation       │  │
│  │  (learned 3D expansion)       │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │  1D → 3D Reshaping            │  │
│  │  → (512, 16, 16, 16)          │  │
│  └──────────────┬─────────────────┘  │
└─────────────────┼────────────────────┘
                  │
       3D Features (512 × 16 × 16 × 16)
                  │
                  ▼

DECODER STAGE (3D Reconstruction)
┌──────────────────────────────────────┐
│         3D Decoder                   │
│                                      │
│  ┌────────────────────────────────┐  │
│  │  Upsample 3D (×2)             │  │
│  │  512 → 256 ch                 │  │
│  │  Size: 32 × 32 × 32           │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │  Conv3D + Instance Norm       │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │  Upsample 3D (×2)             │  │
│  │  256 → 128 ch                 │  │
│  │  Size: 64 × 64 × 64           │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │  Conv3D + Instance Norm       │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │  Upsample 3D (×2)             │  │
│  │  128 → 64 ch                  │  │
│  │  Size: 128 × 128 × 128        │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │  3D AIA Module                │  │
│  │  (3D Attention Refinement)    │  │
│  └──────────────┬─────────────────┘  │
│                 │                    │
│  ┌──────────────▼─────────────────┐  │
│  │  Output Conv3D (1 channel)    │  │
│  │  Tanh Activation              │  │
│  └──────────────┬─────────────────┘  │
└─────────────────┼────────────────────┘
                  │
                  ▼

OUTPUT STAGE
┌──────────────────────────────────────┐
│    Reconstructed CT Volume           │
│    (1 × 128 × 128 × 128)             │
└──────────────────────────────────────┘
```

## Discriminator Architecture

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        PatchGAN DISCRIMINATOR                                │
└─────────────────────────────────────────────────────────────────────────────┘

INPUT
┌──────────────────────────────────────┐
│    CT Volume (Real or Fake)          │
│    (1 × 128 × 128 × 128)             │
└──────────────┬───────────────────────┘
               │
               ▼
┌──────────────────────────────────────┐
│  Conv3D Layer 1 (No Norm)            │
│  1 → 64 channels                     │
│  Kernel: 4×4×4, Stride: 2            │
│  LeakyReLU (0.2)                     │
│  Size: 64 × 64 × 64                  │
└──────────────┬───────────────────────┘
               │
               ▼
┌──────────────────────────────────────┐
│  Conv3D Layer 2 + Instance Norm      │
│  64 → 128 channels                   │
│  Kernel: 4×4×4, Stride: 2            │
│  LeakyReLU (0.2)                     │
│  Size: 32 × 32 × 32                  │
└──────────────┬───────────────────────┘
               │
               ▼
┌──────────────────────────────────────┐
│  Conv3D Layer 3 + Instance Norm      │
│  128 → 256 channels                  │
│  Kernel: 4×4×4, Stride: 2            │
│  LeakyReLU (0.2)                     │
│  Size: 16 × 16 × 16                  │
└──────────────┬───────────────────────┘
               │
               ▼
┌──────────────────────────────────────┐
│  Conv3D Layer 4 + Instance Norm      │
│  256 → 512 channels                  │
│  Kernel: 4×4×4, Stride: 2            │
│  LeakyReLU (0.2)                     │
│  Size: 8 × 8 × 8                     │
└──────────────┬───────────────────────┘
               │
               ▼
┌──────────────────────────────────────┐
│  Output Conv3D                       │
│  512 → 1 channel                     │
│  Kernel: 4×4×4, Stride: 1            │
│  No activation                       │
│  Size: 8 × 8 × 8                     │
└──────────────┬───────────────────────┘
               │
               ▼
OUTPUT
┌──────────────────────────────────────┐
│    Patch-wise Scores                 │
│    (1 × 8 × 8 × 8)                   │
│    Each value = realness of a patch  │
└──────────────────────────────────────┘
```

## Attention In Attention (AIA) Module Detail

```
2D AIA MODULE (Used in Encoder)
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  Input Features (C × H × W)                                 │
│           │                                                 │
│           ├─────────────┬──────────────┬─────────────────┐  │
│           │             │              │                 │  │
│           ▼             ▼              ▼                 │  │
│  ┌────────────────┐ ┌──────────────┐ ┌───────────────┐  │  │
│  │ Channel        │ │ Spatial      │ │ Non-Attention │  │  │
│  │ Attention      │ │ Attention    │ │ Branch        │  │  │
│  │                │ │              │ │               │  │  │
│  │ ┌───────────┐  │ │ ┌─────────┐  │ │ ┌──────────┐  │  │  │
│  │ │ AvgPool   │  │ │ │ Conv2D  │  │ │ │ Conv2D   │  │  │
│  │ │ FC Layers │  │ │ │ Sigmoid │  │ │ │ InstanceN│  │  │
│  │ │ Sigmoid   │  │ │ └─────────┘  │ │ │ ReLU     │  │  │
│  │ └───────────┘  │ │              │ │ └──────────┘  │  │  │
│  │       │        │ │      │       │ │       │       │  │  │
│  └───────┼────────┘ └──────┼───────┘ └───────┼───────┘  │  │
│          │                 │                 │          │  │
│          └────────┬────────┘                 │          │  │
│                   │                          │          │  │
│          Attention Output                Non-Att Out    │  │
│                   │                          │          │  │
│                   └────┬─────────────────────┘          │  │
│                        │                                │  │
│                        ▼                                │  │
│            ┌─────────────────────┐                      │  │
│            │ Weight Generator    │                      │  │
│            │ (Dynamic Weighting) │                      │  │
│            └──────────┬──────────┘                      │  │
│                       │                                 │  │
│                       ▼                                 │  │
│            ┌─────────────────────┐                      │  │
│            │ Weighted Combination│                      │  │
│            │ w1*att + w2*non_att │                      │  │
│            └──────────┬──────────┘                      │  │
│                       │                                 │  │
│                       ▼                                 │  │
│            Output Features (C × H × W)                  │  │
│                                                         │  │
└─────────────────────────────────────────────────────────┘
```

## Loss Function Flow

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              LOSS COMPUTATION                                │
└─────────────────────────────────────────────────────────────────────────────┘

GENERATOR LOSS
┌──────────────────┐
│ Generated CT     │
│ Real CT          │
│ Disc Prediction  │
└────────┬─────────┘
         │
         ├──────────────┬──────────────┬──────────────┬────────────────┐
         │              │              │              │                │
         ▼              ▼              ▼              ▼                ▼
┌─────────────┐ ┌─────────────┐ ┌─────────────┐ ┌──────────────┐ ┌────────┐
│Adversarial  │ │Reconstruction│ │ Projection  │ │ Perceptual   │ │ Total  │
│Loss (LSGAN) │ │ Loss (L1)   │ │ Loss (L1)   │ │ Loss (VGG16) │ │        │
│             │ │              │ │              │ │              │ │  Sum:  │
│ fool disc   │ │ match voxels│ │ match 2D    │ │ match style  │ │ λ₁·L₁+ │
│             │ │              │ │ projections │ │ & content    │ │ λ₂·L₂+ │
│ MSE(D(G),1) │ │ |G-R|       │ │              │ │              │ │ λ₃·L₃+ │
│             │ │              │ │ 3 angles:   │ │ VGG features │ │ λ₄·L₄  │
│             │ │              │ │ -frontal    │ │ on 2D projs  │ │        │
│             │ │              │ │ -lateral    │ │              │ │        │
│             │ │              │ │ -top        │ │              │ │        │
└──────┬──────┘ └──────┬───────┘ └──────┬──────┘ └──────┬───────┘ └───┬────┘
       │               │                │                │             │
       │ λ_adv=1.0     │ λ_recon=10.0   │ λ_proj=5.0     │ λ_perc=1.0  │
       │               │                │                │             │
       └───────────────┴────────────────┴────────────────┴─────────────┘
                                        │
                                        ▼
                            Backpropagate through Generator

DISCRIMINATOR LOSS
┌──────────────────┐
│ Real CT          │
│ Generated CT     │
└────────┬─────────┘
         │
         ├────────────────────┬────────────────────┐
         │                    │                    │
         ▼                    ▼                    ▼
┌─────────────────┐  ┌─────────────────┐  ┌────────────┐
│ Real Prediction │  │ Fake Prediction │  │   Total    │
│   D(Real)       │  │   D(G(x))       │  │            │
│                 │  │                 │  │  (L_real+  │
│ Should be 1     │  │ Should be 0     │  │   L_fake)  │
│ MSE(D(R), 1)    │  │ MSE(D(G), 0)    │  │     /2     │
└────────┬────────┘  └────────┬────────┘  └─────┬──────┘
         │                    │                  │
         └────────────────────┴──────────────────┘
                              │
                              ▼
                  Backpropagate through Discriminator
```

## Data Flow Dimensions

```
Stage                Input Shape              Output Shape            Operation
─────────────────────────────────────────────────────────────────────────────────
Initial              (B,1,128,128)           (B,64,128,128)          Conv2D 7×7
Encoder Block 1      (B,64,128,128)          (B,128,64,64)           Dense+Pool
Encoder Block 2      (B,128,64,64)           (B,256,32,32)           Dense+Pool
Encoder Block 3      (B,256,32,32)           (B,512,16,16)           Dense+Pool
2D AIA               (B,512,16,16)           (B,512,16,16)           Attention
View Fusion          2×(B,512,16,16)         (B,512,16,16)           Fusion
Flatten              (B,512,16,16)           (B,256,512)             Reshape
Transformer          (B,256,512)             (B,512,16,16,16)        Attn+3D
Decoder Block 1      (B,512,16,16,16)        (B,256,32,32,32)        Up+Conv3D
Decoder Block 2      (B,256,32,32,32)        (B,128,64,64,64)        Up+Conv3D
Decoder Block 3      (B,128,64,64,64)        (B,64,128,128,128)      Up+Conv3D
3D AIA               (B,64,128,128,128)      (B,64,128,128,128)      Attention
Output               (B,64,128,128,128)      (B,1,128,128,128)       Conv3D 1×1
─────────────────────────────────────────────────────────────────────────────────

Legend:
  B = Batch size
  Dense = Dense block with growth connections
  Up = Upsample (trilinear or nearest)
  Attn = Multi-head self-attention
```

This diagram provides a complete visual representation of the TRCT-GAN architecture!
